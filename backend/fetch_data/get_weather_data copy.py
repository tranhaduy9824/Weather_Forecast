import requests
import pandas as pd
import numpy as np
import os
from concurrent.futures import ThreadPoolExecutor
from itertools import product

# Danh s√°ch t·ªça ƒë·ªô
latitudes = np.arange(8, 25, 1)
longitudes = np.arange(102, 119, 1)

start_date = "20220101"
end_date = "20250331"  # G·ªôp to√†n b·ªô kho·∫£ng th·ªùi gian

chunk_folder = "backend/dataset/weather_chunks"
os.makedirs(chunk_folder, exist_ok=True)

# Danh s√°ch c·ªôt c·ªë ƒë·ªãnh
PARAMETERS = ["T2M", "QV2M", "PS", "WS10M", "PRECTOTCORR", "CLRSKY_SFC_SW_DWN"]
COLUMNS = ["Datetime", "Latitude", "Longitude"] + PARAMETERS

def fetch_weather_data(lat, lon):
    output_file = f"{chunk_folder}/weather_{lat}_{lon}.csv"

    if os.path.exists(output_file):
        print(f"‚úÖ B·ªè qua {lat}, {lon}, ƒë√£ c√≥ d·ªØ li·ªáu.")
        return

    url = "https://power.larc.nasa.gov/api/temporal/hourly/point"
    params = {
        "parameters": ",".join(PARAMETERS),
        "community": "RE",
        "longitude": lon,
        "latitude": lat,
        "start": start_date,
        "end": end_date,
        "format": "JSON"
    }

    max_retries = 5  # Gi·∫£m s·ªë l·∫ßn th·ª≠
    retry_count = 0
    while retry_count < max_retries:
        try:
            response = requests.get(url, params=params, timeout=15)  # Gi·∫£m timeout xu·ªëng 15s
            response.raise_for_status()

            data = response.json()
            if "properties" not in data or "parameter" not in data["properties"]:
                print(f"‚ö†Ô∏è API kh√¥ng tr·∫£ d·ªØ li·ªáu h·ª£p l·ªá cho {lat}, {lon}. B·ªè qua.")
                return

            parameters_data = data["properties"]["parameter"]
            print(f"üìä API tr·∫£ v·ªÅ d·ªØ li·ªáu cho {lat}, {lon}: {len(parameters_data['T2M'])} th·ªùi ƒëi·ªÉm")

            # Ghi tr·ª±c ti·∫øp v√†o file
            with open(output_file, 'w') as f:
                f.write(",".join(COLUMNS) + "\n")  # Ghi header

                dates = sorted(parameters_data.get("T2M", {}).keys())  # YYYYMMDDHH
                for date_str in dates:
                    dt = pd.to_datetime(date_str, format="%Y%m%d%H").strftime("%Y-%m-%d %H:00:00")
                    row = [dt, str(lat), str(lon)]

                    for param in PARAMETERS:
                        value = parameters_data.get(param, {}).get(date_str, -999)
                        row.append(str(value))

                    f.write(",".join(row) + "\n")

            print(f"‚úÖ D·ªØ li·ªáu ƒë√£ l∆∞u th√†nh c√¥ng t·∫°i {output_file}")
            break

        except (requests.exceptions.Timeout, requests.exceptions.RequestException) as e:
            retry_count += 1
            print(f"‚è≥ L·ªói API t·∫°i {lat}, {lon}: {e}. Th·ª≠ l·∫°i {retry_count}/{max_retries}...")
            if retry_count < max_retries:
                time.sleep(0.5)  # Gi·∫£m t·ª´ 3s xu·ªëng 0.5s
            else:
                print(f"‚ùå B·ªè qua {lat}, {lon} sau {max_retries} l·∫ßn th·ª≠.")

lat_lon_pairs = list(product(latitudes, longitudes))

# TƒÉng max_workers l√™n 20 ƒë·ªÉ t·ªëi ƒëa h√≥a t·ªëc ƒë·ªô
with ThreadPoolExecutor(max_workers=20) as executor:
    executor.map(lambda pair: fetch_weather_data(pair[0], pair[1]), lat_lon_pairs)

print("‚úÖ Ho√†n th√†nh l·∫•y d·ªØ li·ªáu th·ªùi ti·∫øt! D·ªØ li·ªáu ƒë∆∞·ª£c l∆∞u trong backend/dataset/weather_chunks/")